{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "GA3oRLxMRohz",
    "outputId": "0265d425-6a34-4d8f-d7d1-a2980bff964f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\workspace\\py_datascience\\notebooks\\gpt-2\\gpt-2\\gpt-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpt-2'...\n",
      "\"pip3\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "Python was not found but can be installed from the Microsoft Store: https://go.microsoft.com/fwlink?linkID=2082640\n"
     ]
    }
   ],
   "source": [
    "# Select GPT-2 model: 117M, 124M, 355M, 774M, 1558M\n",
    "\n",
    "model_name = '1558M'     # '117M' - smallest model. Set '1558M' for biggest 1.5B model\n",
    "\n",
    "!git clone https://github.com/openai/gpt-2\n",
    "\n",
    "%cd gpt-2\n",
    "\n",
    "!pip3 install -r requirements.txt\n",
    "\n",
    "# Download GPT-2 (selected model, for example 117M)\n",
    "!python3 download_model.py $model_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "0PB1gYfkeZvU",
    "outputId": "bb1368ae-ab69-4312-dcae-f28afaa142c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-11-29 12:01:35.747698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2019-11-29 12:01:35.825340: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2019-11-29 12:01:35.825420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3a7e90ca9e35): /proc/driver/nvidia/version does not exist\n",
      "2019-11-29 12:01:35.879588: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-11-29 12:01:35.883588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29d3800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-11-29 12:01:35.883684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Model prompt >>> "
     ]
    }
   ],
   "source": [
    "# Generate samples by user input. Wait for string \"Model prompt >>>\", enter you text (begin phrase for network) and press Enter\n",
    "\n",
    "!python3 src/interactive_conditional_samples.py --model_name=$model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuKhosKgQHna"
   },
   "outputs": [],
   "source": [
    "# Generate samples to file samples.txt. To stop press STOP button at this cell. How download result samples.txt see last cell\n",
    "\n",
    "!python3 src/generate_unconditional_samples.py --model_name=$model_name | tee samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dC9_n-4HVmHH"
   },
   "outputs": [],
   "source": [
    "# Generate samples with parameters: top_k and temperature. Result saved to samples.txt\n",
    "\n",
    "!python3 src/generate_unconditional_samples.py --model_name=$model_name --top_k 40 --temperature 0.7 | tee samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePBKJi8yZJUO"
   },
   "outputs": [],
   "source": [
    "# Download file samples.txt with generated text (unconditional mode only)\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download('samples.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HXYAbJk4rF1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Gpt-2-All-Models",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
