{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "GA3oRLxMRohz",
    "outputId": "0265d425-6a34-4d8f-d7d1-a2980bff964f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\workspace\\py_datascience\\notebooks\\gpt-2\\gpt-2\\gpt-2\\gpt-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpt-2'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fire>=0.1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
      "Collecting regex==2017.4.5\n",
      "  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
      "Collecting requests==2.21.0\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting tqdm==4.31.1\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\plaidml\\lib\\site-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.13.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\user\\anaconda3\\envs\\plaidml\\lib\\site-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
      "Collecting urllib3<1.25,>=1.21.1\n",
      "  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\envs\\plaidml\\lib\\site-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\plaidml\\lib\\site-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\plaidml\\lib\\site-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.9.11)\n",
      "Building wheels for collected packages: fire, regex\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103533 sha256=878edd0eaa35decd97511bd525182dbb87e56173f3bfac7687cb991b52935877\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\31\\9c\\c0\\07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
      "  Building wheel for regex (setup.py): started\n",
      "  Building wheel for regex (setup.py): finished with status 'done'\n",
      "  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-win_amd64.whl size=247128 sha256=a853d556a9929249285144d8d7f035b4be9b9610659aa32dd217dcbd221c64c2\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\75\\07\\38\\3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
      "Successfully built fire regex\n",
      "Installing collected packages: fire, regex, urllib3, requests, tqdm\n",
      "  Found existing installation: urllib3 1.25.7\n",
      "    Uninstalling urllib3-1.25.7:\n",
      "      Successfully uninstalled urllib3-1.25.7\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "Successfully installed fire-0.2.1 regex-2017.4.5 requests-2.21.0 tqdm-4.31.1 urllib3-1.24.3\n"
     ]
    }
   ],
   "source": [
    "# Select GPT-2 model: 117M, 124M, 355M, 774M, 1558M\n",
    "\n",
    "model_name = '1558M'     # '117M' - smallest model. Set '1558M' for biggest 1.5B model\n",
    "\n",
    "!git clone https://github.com/openai/gpt-2\n",
    "\n",
    "%cd gpt-2\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Download GPT-2 (selected model, for example 117M)\n",
    "!python download_model.py $model_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "0PB1gYfkeZvU",
    "outputId": "bb1368ae-ab69-4312-dcae-f28afaa142c1"
   },
   "outputs": [],
   "source": [
    "# Generate samples by user input. Wait for string \"Model prompt >>>\", enter you text (begin phrase for network) and press Enter\n",
    "\n",
    "!python src/interactive_conditional_samples.py --model_name=$model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuKhosKgQHna"
   },
   "outputs": [],
   "source": [
    "# Generate samples to file samples.txt. To stop press STOP button at this cell. How download result samples.txt see last cell\n",
    "\n",
    "!python src/generate_unconditional_samples.py --model_name=$model_name | tee samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dC9_n-4HVmHH"
   },
   "outputs": [],
   "source": [
    "# Generate samples with parameters: top_k and temperature. Result saved to samples.txt\n",
    "\n",
    "!python3 src/generate_unconditional_samples.py --model_name=$model_name --top_k 40 --temperature 0.7 | tee samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePBKJi8yZJUO"
   },
   "outputs": [],
   "source": [
    "# Download file samples.txt with generated text (unconditional mode only)\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download('samples.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HXYAbJk4rF1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Gpt-2-All-Models",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
