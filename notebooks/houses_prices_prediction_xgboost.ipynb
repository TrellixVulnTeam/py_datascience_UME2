{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 300) (1459, 300)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "shuffle must be True or False; got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a9072064e7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNSPLIT_WARNING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             raise TypeError(\"shuffle must be True or False;\"\n\u001b[1;32m--> 297\u001b[1;33m                             \" got {0}\".format(shuffle))\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: shuffle must be True or False; got 5"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "CLASS = False  # Whether classification or regression\n",
    "SCORE_MIN = True  # Optimizing score through minimum\n",
    "k = 5  # Number of folds\n",
    "best_score = 10\n",
    "best_params = None\n",
    "best_iter = None\n",
    "\n",
    "train_name = 'C:\\\\Users\\\\user\\\\py_datascience\\\\Datasets\\\\train.csv'\n",
    "test_name = 'C:\\\\Users\\\\user\\\\py_datascience\\\\Datasets\\\\test.csv'\n",
    "submission_name = 'C:\\\\Users\\\\user\\\\py_datascience\\\\Datasets\\\\sample_submission.csv'\n",
    "submission_col = 'SalePrice'\n",
    "submission_target = 'test_sub1.csv'\n",
    "\n",
    "# Read files\n",
    "train = pd.read_csv(train_name)\n",
    "train = train.fillna(-1)\n",
    "test = pd.read_csv(test_name)\n",
    "test = test.fillna(-1)\n",
    "submission = pd.read_csv(submission_name)\n",
    "# Extract target\n",
    "target = train['SalePrice']\n",
    "del train['SalePrice']\n",
    "\n",
    "# Label nominal variables to numbers\n",
    "columns = train.columns.values\n",
    "nom_numeric_cols = ['MSSubClass']\n",
    "dummy_train = []\n",
    "dummy_test = []\n",
    "for col in columns:\n",
    "    # Only works for nominal data without a lot of factors\n",
    "    if train[col].dtype.name == 'object' or col in nom_numeric_cols:\n",
    "        dummy_train.append(pd.get_dummies(train[col].values.astype(str), col))\n",
    "        dummy_train[-1].index = train.index\n",
    "        dummy_test.append(pd.get_dummies(test[col].values.astype(str), col))\n",
    "        dummy_test[-1].index = test.index\n",
    "        del train[col]\n",
    "        del test[col]\n",
    "train = pd.concat([train] + dummy_train, axis=1)\n",
    "test = pd.concat([test] + dummy_test, axis=1)\n",
    "\n",
    "# Use only common columns\n",
    "columns = []\n",
    "for col_a in train.columns.values:\n",
    "    if col_a in test.columns.values:\n",
    "        columns.append(col_a)\n",
    "train = train[columns]\n",
    "test = test[columns]\n",
    "\n",
    "# CV\n",
    "train = np.array(train)\n",
    "target = np.log(np.array(target))  # Changes to Log\n",
    "test = np.array(test)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "if CLASS:\n",
    "    kfold = StratifiedKFold(target, k)\n",
    "else:\n",
    "    kfold = KFold(train.shape[0], k)\n",
    "\n",
    "early_stopping = 50\n",
    "\n",
    "param_grid = [\n",
    "              {'silent': [1],\n",
    "               'nthread': [2],\n",
    "               'eval_metric': ['rmse'],\n",
    "               'eta': [0.03],\n",
    "               'objective': ['reg:linear'],\n",
    "               'max_depth': [5, 7],\n",
    "               'num_round': [1000],\n",
    "               'subsample': [0.2, 0.4, 0.6],\n",
    "               'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "               }\n",
    "              ]\n",
    "\n",
    "# Hyperparmeter grid optimization\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(params)\n",
    "    # Determine best n_rounds\n",
    "    xgboost_rounds = []\n",
    "    for train_index, test_index in kfold:\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "        xg_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        xg_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "        num_round = params['num_round']\n",
    "        xgclassifier = xgboost.train(params, xg_train, num_round,\n",
    "                                     watchlist,\n",
    "                                     early_stopping_rounds=early_stopping);\n",
    "        xgboost_rounds.append(xgclassifier.best_iteration)\n",
    "\n",
    "    num_round = int(np.mean(xgboost_rounds))\n",
    "    print('The best n_rounds is %d' % num_round)\n",
    "    # Solve CV\n",
    "    rmsle_score = []\n",
    "    for cv_train_index, cv_test_index in kfold:\n",
    "        X_train, X_test = train[cv_train_index, :], train[cv_test_index, :]\n",
    "        y_train, y_test = target[cv_train_index], target[cv_test_index]\n",
    "\n",
    "        # train machine learning\n",
    "        xg_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        xg_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "        xgclassifier = xgboost.train(params, xg_train, num_round);\n",
    "\n",
    "        # predict\n",
    "        predicted_results = xgclassifier.predict(xg_test)\n",
    "        rmsle_score.append(np.sqrt(mean_squared_error(y_test, predicted_results)))\n",
    "\n",
    "    if SCORE_MIN:\n",
    "        if best_score > np.mean(rmsle_score):\n",
    "            print(np.mean(rmsle_score))\n",
    "            print('new best')\n",
    "            best_score = np.mean(rmsle_score)\n",
    "            best_params = params\n",
    "            best_iter = num_round\n",
    "    else:\n",
    "        if best_score < np.mean(rmsle_score):\n",
    "            print(np.mean(rmsle_score))\n",
    "            print('new best')\n",
    "            best_score = np.mean(rmsle_score)\n",
    "            best_params = params\n",
    "            best_iter = num_round\n",
    "\n",
    "# Solution using best parameters\n",
    "print('best params: %s' % best_params)\n",
    "print('best score: %f' % best_score)\n",
    "xg_train = xgboost.DMatrix(train, label=target)\n",
    "xg_test = xgboost.DMatrix(test)\n",
    "watchlist = [(xg_train, 'train')]\n",
    "num_round = best_iter  # already int\n",
    "xgclassifier = xgboost.train(best_params, xg_train, num_round, watchlist);\n",
    "submission[submission_col] = np.exp(xgclassifier.predict(xg_test))\n",
    "submission.to_csv(submission_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
